\chapter{اختصاص منابع پردازشی در شبکه اینترنت اشیاء}\label{chap:system_model}
  \thispagestyle{empty}
  \section{مقدمه}
    در این فصل ابتدا مدل ریاضی مربوط به تخصیص منابع پردازشی در شبکه‌ی اینترنت اشیاء را شرح می‌دهیم. 
    در این نوع تخصیص منابع، تعدادی وظیفه و منبع پردازشی داریم که وظیفه‌ها باید برای پردازش داده‌های جمع‌آوری شده توسط حسگر‌های خود به این منابع پردازشی ارسال شوند و در آن‌جا پردازش شوند.

    پس از معرفی و فرمول بندی مسئله، چالش‌ها و دلایل پیچیدگی حل این مسئله را بررسی می‌کنیم.
  \section{مدل سیستم}
    \begin{figure}[h]
      \centerline{\includegraphics[width=12cm]{graphics/one_to_one/system_model}}
      \caption{دید کلی از مدل سیستم \cref{chap:system_model}}
      \label{fig:system_model}
    \end{figure}

	    \cref{fig:system_model} مثالی از مدل سیستم این فصل را برای یک سرویس که دارای دو حسگر می‌باشد نشان می‌دهد. همانطور که دیده می‌شود و قبلا هم صحبت شد مدل سیستم از چهار لایه‌ی اصلی تشکیل می‌شود که از پایین به بالا عبارتند از لایه حسگر، لبه، مه و ابر که در \cref{fig:system_model} به خوبی این لایه‌ها دیده می‌شوند. 
    
    مجموعه‌ی گره‌های لایه‌ی ابر، مه، لبه و حسگر را به ترتیب با $C$، $F$، $E$ و $S$ نمایش می‌دهیم. همچنین مجموعه منابع موجود در هر گره پردازشی را با $R$ نمایش می‌دهیم که در این پایان‌نامه این مجموعه را شامل سه منبع پردازشی پردازنده\LTRfootnote{CPU}، حافظه\LTRfootnote{RAM} و همچنین دیسک\LTRfootnote{Storage} درنظر می‌گیریم. 
    \begin{subequations}\label{eqn:def_sets}
    	\begin{align}
    	C = \{v_1^c, v_2^c, ..., v_{|C|}^c\} , c \in C\\
    	F = \{v_1^f, v_2^f, ..., v_{|F|}^f\} , f \in F\\
    	E = \{v_1^e, v_2^e, ..., v_{|E|}^e\} , e \in E\\
    	S = \{v_1^s, v_2^s, ..., v_{|S|}^s\} , s \in S\\
    	R = \{CPU, RAM, Storage\} , r \in R
    	\end{align}
    \end{subequations}
    نماد مورد استفاده در منابع پردازشی $\sigma$ است به‌این‌صورت که به عنوان مثال می‌توان گفت که $\sigma_c^r$ برابر است با مجموع ظرفیت پردازشی از منبع $r \in R$ در گره $c \in C$. 
    همچنین در مورد مجموعه‌های تعریف‌‌شده در \cref{eqn:def_sets} معادل حرف کوچک از هر محموعه را به عنوان نماینده‌ای از اعضای آن مجموعه درنظر می‌گیریم، مثلا به‌این‌صورت که $c$ نشان‌دهنده‌ی یکی از گره‌های موجود در لایه‌ی ابر یعنی $C$ است. همچنین تعداد اعضای موجود در هر مجموعه را با علامت $||$ مشخص کرده‌ایم. 
    مجموعه‌ی مهم دیگری که تعریف می‌شود مجموعه‌ی وظیفه‌های موجود در شبکه است. این وظیفه‌ها توسط گره‌های حسگری تولید می‌شوند و مجموعه‌ی متناسب با آن را  با $T$ نشان می‌دهیم. 
    \begin{equation}\label{eqn:def_sets_tasks}
    	T = \{t_1, t_2, ..., t_{|T|}\}
    \end{equation}
	که در \cref{eqn:def_sets_tasks} لازم است هر وظیفه به صورت دقیق‌تر تعریف شود، لذا برای هر وظیفه چهار ویژگی درنظر گرفته شده است که در ادامه به تفصیل آورده می‌شود. 
	\begin{equation}\label{eqn:def_task}
	t \in T => t = (w_t, \delta_t, N_t, f_t^r(\lambda_t))
	\end{equation}
	در \cref{eqn:def_task} $w_t$، $N_t$ و $\delta_t$ به ترتیب میزان حجم پردازنده مورد نیاز، بیشترین تعداد از وظیفه‌های مشابه و همچنین حداقل زمان مورد نیاز برای پردازش کامل، برای وظیفه $t \in T$ را نشان می‌دهد. واحد اندازه‌گیری در این سه متغیر می‌تواند به سلیقه‌ی استفاده کننده تغییر کند اما به عنوان مثال می‌توان گفت که واحد اندازه‌گیری میزان حجم پردازنده را گیگاهرتز\LTRfootnote{GHz} در نظر گرفت  و یا واحد اندازه‌گیری در حداقل زمان مورد نیاز میلی‌ثانیه انتخاب کرد. در میان ویژگی‌های مربوط به یک وظیفه یک تابع به نام $f_t^r$ نیز دیده می‌شود که این تابع نرخ استفاده وظیفه از منبع $r \in R$ را نشان می‌دهد که ورودی آن متغیری به‌نام $\lambda$ است که نشان‌دهنده‌ی نرخ ورود وظیفه به گره پردازشی است که با توجه به مدل سیستم ما از جنس فرآیند تصادفی پوآسون است. 
	
	همانطور که در قسمت مقدمه گفته شد در مورد تاخیرها، تاخیر انتقال را صرفا در نظر می‌گیریم که بدین صورت که مثلا $\tau_{s,c}^{tr}$ برابر است با میزان تاخیر انتقال از گره حسگری $s \in S$ تا گره پردازشی $c \in C$. 
	
	نماد دیگری که در ادامه از آن استفاده می‌شود نماد $\pi$ است که به میزان هزینه‌های مربوط به پردازش را در گره‌های پردازشی نشان می‌دهد. برای جلوگیری از پیچیدگی بیشتر صورت مسئله برای هر گره پردازشی یک هزینه برای تمامی منابع آن گره در نظر گرفته می‌شود که به عنوان یک ضریب در رابطه‌های بعدی از آن استفاده خواهد شد. به عنوان مثال تمامی هزینه‌های پردازشی در گره $c \in C$ با نماد $\pi_c$ نمایش داده می‌شود و مفهوم آن بدین صورت است که مثلا برای استفاده از پردازنده در این گره به ازای هر واحد پردازشی در ثانیه لازم است که مقدار $\pi_c$ واحد پول پرداخته شود. 
	\subsection{متغیرها}
	در این بخش قرار است در مورد متغیرهای استفاده شده در مسئله به تفصیل صحبت شود. 
	در مورد محل پردازش وظیفه ها، سه متغیر دودویی به صورت زیر تعریف می‌شود:
	    \begin{subequations}\label{eqn:def_variable_x}
		\begin{align}
		x_{t,c} =
		\begin{cases}
		1 & \text{وظیفه $t \in T$ در گره $c \in C$ پردازش می‌شود } \\
		0 & \text{در غیر این‌صورت}
		\end{cases}
		\end{align}
		
		\begin{align}
		x_{t,f} =
		\begin{cases}
		1 & \text{وظیفه $t \in T$ در گره $f \in F$ پردازش می‌شود } \\
		0 & \text{در غیر این‌صورت}
		\end{cases}
		\end{align}
		
		\begin{align}
		x_{t,e} =
		\begin{cases}
		1 & \text{وظیفه $t \in T$ در گره $e \in E$ پردازش می‌شود } \\
		0 & \text{در غیر این‌صورت}
		\end{cases}
		\end{align}
	\end{subequations}
	دسته دوم متغیر که با $\beta$ نشان داده می‌شود متغیر پیوسته مسئله است که در \cref{eqn:def_variable_beta} معرفی می‌شود و مربوط است به حجم ارسالی جریان وظیفه‌ها بین گره ها، به عنوان مثال $\beta_{t,s,c}$ برابر است با میزان جریان ارسالی از نوع وظیفه‌ی $t \in T$، از گره حسگری $s \in S$ به گره پردازشی $c \in C$.
	\begin{subequations}\label{eqn:def_variable_beta}
		\begin{align}
		0 \le \beta_{t,s,c} \le \lambda_{t,s}  \quad \forall{t \in T}, \forall{s \in S}, \forall{c \in C} \\
		0 \le \beta_{t,s,f} \le \lambda_{t,s}  \quad \forall{t \in T}, \forall{s \in S}, \forall{f \in F} \\
		0 \le \beta_{t,s,e} \le \lambda_{t,s}  \quad \forall{t \in T}, \forall{s \in S}, \forall{e \in E}
		\end{align}
	\end{subequations}
 
		همچنین در مورد ورودی‌های مسئله داریم:
	\begin{equation}\label{eqn:def_variable_lambda_t_s}
	\lambda_{t,s} = \text{میزان نرخ پوآسون تولید وظیفه $t \in T$ در گره $s \in S$}
	\end{equation}
	درواقع متغیر \cref{eqn:def_variable_lambda_t_s} به عنوان ورودی مسئله تعریف می‌شود و در جریان حل مسئله مقدارش تعیین نمی‌شود و عملا متغیرهای اصلی در مسئله دو دسته هستند که دسته اول از جنس متغیر گسسته دودویی هستند و دسته دوم متغیرهای پیوسته. تا اینجای کار احتمالا خواننده می‌تواند حدس بزند که مسئله بهینه‌سازی که در ادامه شکل می‌گیرد از نوع مسئله‌های مخلوط عدد صحیح \LTRfootnote{Mixed-Integer} خواهد بود. در مورد خطی بودن یا نبودن نیز می‌دانیم که کار کردن با مسئله بهینه‌سازی خطی به مراتب راحت تر از غیرخطی خواهد بود، لذا به نظر می‌رسد که لازم است مسئله به‌گونه‌ای مدل شود که خطی باشد و یا اینکه خطی‌سازی شود. 
	
	در ادامه قیدهای موجود در مدل‌سازی بررسی می‌شود. 
    \subsection{قیدها}
    اولین قید مورد بررسی به عنوان یک متغیر میانی معرفی می‌شود به این صورت که مجموع جریان‌های ورودی به یک گره پردازشی به عنوان یک متغیر میانی که در \cref{eqn:constraint_load_conservation_computing_nodes} نشان داده شده است نمایش داده می‌شود. باید توجه کرد که جنس متغیر تعریف شده در \cref{eqn:def_variable_lambda_t_s} و متغیر میانی تعریف شده در \cref{eqn:constraint_load_conservation_computing_nodes} یکسان است اما مفهوم آن‌ها اندکی با هم فرق دارد، اولی نرخ خروج وظیفه از گره‌های حسگری را نشان می‌دهد در صورتیکه دومی نرخ ورود وظیفه به گره‌های پردازشی را بیان می‌کند. 
    \begin{subequations}\label{eqn:constraint_load_conservation_computing_nodes}
    	\begin{align}
    	\lambda_{t,c} = \sum_{s\in S}\beta_{t,s,c} \quad \forall{t \in T}, \forall{c \in C} \\
    	\lambda_{t,f} = \sum_{s\in S}\beta_{t,s,f} \quad \forall{t \in T}, \forall{f \in F} \\
    	\lambda_{t,e} = \sum_{s\in S}\beta_{t,s,e} \quad \forall{t \in T}, \forall{e \in E}
    	\end{align}
    \end{subequations}
	قید \cref{eqn:constraint_request_flow_existence} به این صورت است که رابطه‌ی بین متغیرهای پیوسته و گسسته(دودویی) مسئله را مشخص می‌کند. بدین صورت که اگر سمت راست نامساوی صفر باشد آنگاه سمت چپ نیز ناچارا لازم است که صفر باشد و این یعنی جریانی وجود ندارد، همچنین اگر سمت چپ غیرصفر باشد آنگاه متغیر دودویی سمت راست به ناچار باید مقدارش یک باشد. 
	\begin{subequations}\label{eqn:constraint_request_flow_existence}
		\begin{align}
		\frac{\lambda_{t,c}}{\sum_{s\in S}\lambda_{t,s}} \le x_{t,c} \quad \forall{t \in T}, \forall{c \in C} \\
		\frac{\lambda_{t,f}}{\sum_{s\in S}\lambda_{t,s}} \le x_{t,f} \quad \forall{t \in T}, \forall{f \in F} \\
		\frac{\lambda_{t,e}}{\sum_{s\in S}\lambda_{t,s}} \le x_{t,e} \quad \forall{t \in T}, \forall{e \in E}
		\end{align}
	\end{subequations}
	قید \cref{eqn:constraint_load_managing} مربوط به مدیریت منابع است به این‌ صورت که مجموع منابع استفاده شده در هر گره پردازشی لازم است از کل منابع موجود در آن گره کم‌تر باشد. در این قسمت در مورد تابع$f_t^r(\lambda)$ بیشترین صحبت می‌کنیم. همانطور که مشاهده می‌شود این تابع یک تابع خطی از ورودی‌اش می‌باشد و نشان می‌دهد که وظیفه $t$ با چه نرخی منبع پردازشی از نوع $r$ را مصرف می‌کند بابراین لازم است که واحد آن از جنس مقدار منبع بر ثانیه باشد. در مورد ضرایب استفاده شده در این تابع می‌توان گفت که دو ضریب $k_1^r$ و $k_2^r$ بسته با نوع منبع و همچنین مشخصات گره محاسباتی تبیین می‌شوند که مقادیر آن‌ها در جدولی در ادامه خواهد آمد. در نهایت می‌توان گفت که مقدار خروجی این تابع وابسته به نوع وظیفه،نوع گره و میزان جریان ورودی به گره است. 
	\begin{subequations}\label{eqn:constraint_load_managing}
		\begin{align}
		&\sum_{t \in T}x_{t,c}f_t^r(\lambda_{t,c}) \le \sigma_c^r \quad \forall{r \in R}, \forall{c \in C} \\
		&x_{t,c}f_t^r(\lambda_{t,c}) = k_1^rx_{t,c}\lambda_{t,c} + k_2^rx_{t,c} \label{eqn:def_psi_appear} \\
		&\psi_{t,c} \triangleq x_{t,c}\lambda_{t,c} \Rightarrow 0 \leq \psi_{t,c} \leq \lambda_{t,c} \label{eqn:def_psi} \\
		&Q(x_{t,c}-1)+\lambda_{t,c} \leq \psi_{t,c} \leq x_{t,c}Q \label{eqn:def_Q_appear}\\
		&\notag Q = \max_{{t \in T},{c \in C}} \lambda_{t,c} \\
		&\notag =\max_{{t \in T},{c \in C}} \sum_{s \in S}\beta_{t,s,c} \\
		&\notag =\sum_{s\in S} \max_{{t \in T},{c \in C}} \beta_{t,s,c} \\
		&=\sum_{s \in S}\lambda_{t,s} \label{eqn:def_Q}
		\end{align}
	\end{subequations}
	همانطور که در \cref{eqn:def_psi_appear} دیده می‌شود دو متغیر مسئله یعنی $x$ و $\lambda$ که مجموع خطی از $\beta$ است، به صورت حاصلضرب درآمده‌اند که این اتفاق مسئله را از حالت خطی خارج می‌کند و همانجایی است که لازم است مسئله خطی‌سازی شود. برای این کار یک متغیر میانی در \cref{eqn:def_psi} تعریف می‌شود. با این کار حاصلضرب ایجاد شده از بین می‌رود و قیدهای مسئله تا این جای کار همچنان خطی باقی می‌مانند. اما همانطور که می‌دانیم ایجاد یک متغیر جدید هزینه‌هایی هم دارد که باید بهای آن پرداخته شود و این بها به وجود آمدن قیدهای جدید در مسئله است. 
	قبل از بررسی قیدهای اضافه شده لازم است که یک نماد دیگر معرفی شود. این نماد که با حرف $Q$ نشان داده شده است اولین بار در \cref{eqn:def_Q_appear} دیده شده است که برابر با مقدار بالقوه‌ی بیشترین جریان ورودی به یک گره محاسباتی، که در خاص‌ترین حالت می‌توان گفت که تمام جریان تولیدی وظیفه‌های موجود در شبکه برای پردازش به یک گره بروند در این صورت $Q$ برابر است با مچموع جریان تولید شده‌ی همه‌ی وظیفه‌ها در تمام حسگرها که در \cref{eqn:def_Q} نحوه‌ی محسابه آنچه که گفته شد دیده می‌شود. 
	
	در مورد متغیر میانی تعریف شده در \cref{eqn:def_psi} قیدهای مربوطه در \cref{eqn:constraint_psi} دیده می‌شود. 
	\begin{subequations}\label{eqn:constraint_psi}
		\begin{align}
		&0 \leq \psi_{t,c} \leq \lambda_{t,c} \\
		&Q(x_{t,c}-1)+\lambda_{t,c} \leq \psi_{t,c} \leq x_{t,c}Q \quad \forall{t\in T}, \forall{c \in C} \\
		&0 \leq \psi_{t,f} \leq \lambda_{t,f} \\
		&Q(x_{t,f}-1)+\lambda_{t,f} \leq \psi_{t,f} \leq x_{t,f}Q \quad \forall{t \in T}, \forall{f \in F} \\
		&0 \leq \psi_{t,e} \leq \lambda_{t,e} \\
		&Q(x_{t,e}-1)+\lambda_{t,e} \leq \psi_{t,e} \leq x_{t,e}Q \quad \forall{t \in T}, \forall{e \in E}
		\end{align}
	\end{subequations}
	حال با تعریف متغیر \cref{eqn:def_psi} می‌توان قید موجود در \cref{eqn:constraint_load_managing} را به صورت \cref{eqn:constraint_load_managing_new} دوباره نویسی کرد. 
	\begin{subequations}\label{eqn:constraint_load_managing_new}
		\begin{align}
		\sum_{t \in T}k_1^r\psi_{t,c}+k_2^rx_{t,c} \le \sigma_c^r \quad \forall{r \in R}, \forall{c \in C} \\
		\sum_{t \in T}k_1^r\psi_{t,f}+k_2^rx_{t,f} \le \sigma_f^r \quad \forall{r \in R}, \forall{f \in F} \\
		\sum_{t \in T}k_1^r\psi_{t,e}+k_2^rx_{t,e} \le \sigma_e^r \quad \forall{r \in R}, \forall{e \in E}
		\end{align}
	\end{subequations}
	قید بعدی که مورد بررسی قرار می‌گیرد قید مربوط به تاخیرهاست. ابتدا تاخیر موجود در شبکه از زمانی که وظیفه ارسال می‌شود تا لحظه‌ای که وظیفه پردازش می‌شود به صورت \cref{eqn:def_delay} تعریف می‌شود، همانطور که دیده می‌شود این تعریف از دو بخش تاخیر انتقال و تاخیر صف تشکیل شده است. 
همانطور که در قسمت مقدمه گفته شد برای محاسبه‌ی تاخیر صف در یک سیستم نوع اول، دو متغیر نرخ ورود بسته‌ها $\lambda$ و نرخ پردازش آن‌ها $\mu$ لازم است. در مدل ما نرخ ورود وظیفه‌ها در هر گره به صورت یک متغیر میانی تغریف شده است اما در مورد نرخ پردازش بسته‌ها به توجه به نوع بسته و همچنین میزان قدرت پردازشی گره رابطه‌ی \cref{eqn:def_mu} در نظر گرفته شده‌است. با جایگزین کردن موارد گفته شده رابطه‌ی نهایی تاخیر موجود در گره‌ها به صورت \cref{eqn:def_delay_final} نمایش داده می‌شود. 
	\begin{subequations}
		\begin{align}
			&\tau_{t,c} = \tau_{t,s,c}^{tr} + \frac{1}{\mu_{t,c}-\lambda_{t,c}} \label{eqn:def_delay}\\
			&\frac{1}{\mu_{t,c}} = \frac{w_t}{f_t^{cpu}(\lambda_{t,c})} \label{eqn:def_mu}\\
			&f_t^{cpu}(\lambda_{t,c}) = k_1^{cpu}\lambda_{t,c}+k_2^{cpu} \\
			&\tau_{t,c} = \tau_{t,s,c}^{tr} + \frac{w_t}{(k_1^{cpu}-w_t)\lambda_{t,c} + k_2^{cpu}} \label{eqn:def_delay_final}
		\end{align}
	\end{subequations}
	در نهایت قید مربوط به تاخیر در \cref{eqn:constraint_delay} آورده شده است که با ساده سازی به صورت \cref{eqn:constraint_delay_new} نمایش داده می‌شود. 
	\begin{subequations}
		\begin{align}
			&x_{t,c}\tau_{t,c}\le \delta_t \quad \forall{t \in T}, \forall{s \in S}, \forall{c \in C} \label{eqn:constraint_delay} \\			
			&\notag x_{t,c}\lambda_{t,c}(k_1^{cpu}-w_t)\tau^{tr}_{t,s,c} + \\ 
			&\notag x_{t,c}k_2^{cpu}\tau_{t,s,c}^{tr}+w_t x_{t,c}-k_2^{cpu}\delta_t \\ &-(k_1^{cpu}-w_t)\delta_t\lambda_{t,c} \le 0 \quad \forall{t \in T}, \forall{s \in S}, \forall{c \in C} \label{eqn:constraint_delay_new}
		\end{align}
	\end{subequations}
	در صورت استفاده از متغیر میانی \cref{eqn:def_psi} در قید \cref{eqn:constraint_delay_new} می‌توان این قید را به صورت \cref{eqn:constraint_delay_last} به صورت نهایی نمایش داد. 
	\begin{subequations}\label{eqn:constraint_delay_last}
		\begin{align}
		&\notag\psi_{t,s,c}(k_1^{cpu}-w_t)\tau^{tr}_{t,s,c} + \\ &\notag x_{t,c}k_2^{cpu}\tau_{t,s,c}^{tr}+w_t x_{t,c}-k_2^{cpu}\delta_t \\ &-(k_1^{cpu}-w_t)\delta_t\lambda_{t,c} \le 0
		\end{align}
		\begin{align}
		&\notag\psi_{t,s,f}(k_1^{cpu}-w_t)\tau^{tr}_{t,s,f} + \\ &\notag x_{t,f}k_2^{cpu}\tau_{t,s,f}^{tr}+w_t x_{t,f}-k_2^{cpu}\delta_t \\ &-(k_1^{cpu}-w_t)\delta_t\lambda_{t,f} \le 0
		\end{align}
		\begin{align}
		&\notag\psi_{t,s,e}(k_1^{cpu}-w_t)\tau^{tr}_{t,s,e} + \\ &\notag x_{t,e}k_2^{cpu}\tau_{t,s,e}^{tr}+w_t x_{t,e}-k_2^{cpu}\delta_t \\ &-(k_1^{cpu}-w_t)\delta_t\lambda_{t,e} \le 0
		\end{align}
	\end{subequations}
	دیگر قیدی که مورد بررسی قرار می‌گیرد قید مربوط به پایداری صف در گره‌هاست که در مورد آن در مقدمه توضیح داده شد. در مدل ما این قید به صورت \cref{eqn:constraint_queue_stability} آورده شده‌است. نکته‌ی قابل تاملی که به ساده سازی مسئله کمک می‌کند \cref{eqn:lambda_eqn} است که دلیل آن این است که زمانیکه چریانی از یک وظیفه به سمت یک گره وجود دارد، می‌توان با حتمیت گفت که متغیر دودویی مربوط به آن وظیفه و گره مقدارش یک است و بالعکس. 
	\begin{subequations}\label{eqn:constraint_queue_stability}
		\begin{align}
		&x_{t,c}(\lambda_{t,c} < \mu_{t,c}) => x_{t,c}(\lambda_{t,c} + \epsilon \le \mu_{t,c}) \\
		&x_{t,c}\lambda_{t,c} = \lambda_{t,c} \label{eqn:lambda_eqn}\\
		&=> \epsilon x_{t,c} - k_1^{cpu}\lambda_{t,c} - k_2^{cpu} + w_t\lambda_{t,c} \le 0 \quad \forall{t \in T}, \forall{c \in C} \\
		&\epsilon x_{t,f} - k_1^{cpu}\lambda_{t,f} - k_2^{cpu} + w_t\lambda_{t,f} \le 0 \quad \forall{t \in T}, \forall{f \in F} \\
		&\epsilon x_{t,e} - k_1^{cpu}\lambda_{t,e} - k_2^{cpu} + w_t\lambda_{t,e} \le 0 \quad \forall{t \in T}, \forall{e \in E}
		\end{align}
	\end{subequations}

	تا اینجای کار بین تمام قیدهای گفته شده یک ویژگی مشترک وجود داشت و این بود که در تمامی قیدهای گفته شده قابلیت قید هر گره محاسباتی از سایر گره‌ها جدا بود و نمی‌توان قیدها را به گونه‌ای تجزیه کرد که هر گره محسابتی صرفا قید مربوط به خودش را ببیند که این اتفاق یک اتفاق خوشایند است که در ادامه علت خوشایند بودن آن مشخص خواهد شد. اما در دوقید بعد خواهیم دید که بین گره‌های محاسباتی به نوعی اتصال ایجاد خواهد شد. 
	اولین قید اتصالی که مورد بررسی قرار می‌گیرد مربوط به وجود تعادل بین جریان ورودی وظیفه‌ها و جریان خروجی وظیفه‌هاست. این قید در \cref{eqn:constraint_load_conservation_sensor_nodes_coupling} آورده شده‌است. و همانطور که می‌بینید در این قید نمی‌توانیم برای هرگره پردازشی یک رابطه جدا مشخص کنیم. 
	\begin{equation}\label{eqn:constraint_load_conservation_sensor_nodes_coupling}
	\lambda_{t,s} = \sum_{e \in E} \beta_{t,s,e} + \sum_{f 	\in F} \beta_{t,s,f}
	+\sum_{c \in C}\beta_{t,s,c} \quad \forall{t \in T}, \forall{s \in S}
	\end{equation} 
	قید بعدی مربوط به شرط لازم برای پردازش همه‌ی وظیفه‌هاست بدین صورت که هر وظیفه حداقل باید در یکی از گره‌های پردازشی موجود در شبکه پردازش شود. در این پایان‌نامه این فرض در نظر گرفته شده‌است که یک وظیفه می‌تواند در چندین گره پردازشی نیز پردازش شود این فرض این قابلیت را به مسئله اضافه می‌کند که وظیفه‌ها به صورت افقی مقیاس‌پذیر\LTRfootnote{Scalable} باشند به این معنی که بر روی تعداد وظیفه‌های از جنس یک سرویس می‌تواند محدودیتی وجود ندارد. برای این کار یک متغیر تحت عنوان $N_t$ در نظر گرفته می‌شود که هرچقدر این عدد بزرگتر باشد مقیاس‌پذیری سیستم بیشتر است. قید مربوطه در \cref{eqn:constraint_scalability_coupling} آورده شده‌است. به وضوح در این قید نیز دیده می‌شود که نمی‌توان رابطه‌ی مستقلی برای هر یک از گره‌های پردازشی پیدا کرد. 
	\begin{equation}\label{eqn:constraint_scalability_coupling}
		1 \le \sum_{e \in E}x_{t,e} + \sum_{f \in F}x_{t,f} + \sum_{c \in C}x_{t,c} \le N_t \quad \forall{t \in T}
	\end{equation}
	
	\subsection{تابع هدف}
	در گام بعدی لازم است که تابع هدف\LTRfootnote{Objective function} تعریف شود، برای این کار لازم که ابتدا هدف از صورت مسئله مشخص شود. اولین هدف در این مقاله کم کردن هزینه‌های مربوط به کل شبکه است. می‌دانیم که پردازش وظیفه‌ها در گره‌های پردازشی یک فرآیند هزینه‌بر است، حال صورت مسئله بهینه‌سازی با این هدف تعریف می‌شود که مجموع کل هزینه‌های موچود در شبکه کمترین مقدار ممکن باشد. برای این‌کار لازم است از متغیرهای دودویی مسئله$x$، تابع مشخص کننده نرخ مصرف منبع پردازشی$f$ و همچنین واحد هزینه‌های پردازشی $\pi$ استفاده شود. درنهایت تابع هدف به صورت \cref{eqn:objective_func} تعریف می‌شود. 
	\begin{subequations}\label{eqn:objective_func}
		\begin{align}
		& \notag \min \sum_{t \in T}\sum_{e \in E} (x_{t,e}\pi_e\sum_{r \in R}f_t^r(\lambda_{t,e})) \\
		&\notag + \sum_{t \in T}\sum_{f \in F} (x_{t,f}\pi_f\sum_{r \in R}f_t^r(\lambda_{t,f})) \\
		& + \sum_{t \in T}\sum_{c \in C} (x_{t,c}\pi_c\sum_{r \in R}f_t^r(\lambda_{t,c}))
		\end{align}
		\begin{align}
		& \notag \min \sum_{t \in T}\sum_{e \in E} x_{t,e}\Gamma_{t,e} \\
		& \notag + \sum_{t \in T}\sum_{f \in F} x_{t,f}\Gamma_{t,f} \\
		& + \sum_{t \in T}\sum_{c \in C} x_{t,c}\Gamma_{t,c}
		\end{align}
		\begin{align}\label{eqn:def_Gamma}
		&\notag \Gamma_{t,e} = \pi_e((k_1^{cpu}+k_1^{ram}+k_1^{storage})\lambda_{t,e} \\
		&\notag +k_2^{cpu}+k_2^{ram}+k_2^{storage}) \\
		& = \pi_e(K_1\lambda_{t,e}+K_2)
		\end{align}
		\begin{align}
		&\notag x_{t,e}\Gamma_{t,e} = K_1\pi_ex_{t,e}\lambda_{t,e} + K_2\pi_ex_{t,e} \\
		&= K_1\pi_e\psi_{t,e} + K_2\pi_ex_{t,e}
		\end{align}
	\end{subequations}
	در \cref{eqn:def_Gamma} یک متغیر میانی تعریف شده است، که به ساده نویسی مسئله کمک شایانی می‌کند. 
	درنهایت با ساده‌سازی‌های انجام شده و همچنین استفاده از متغیرهای کمکی می‌توان گفت که تابع هدف نهایی به صورت \cref{eqn:objective_func_final} نوشته می‌شود. 
	\begin{align}
		&\min \sum_{t \in T}\sum_{e \in E} 				K_1\pi_e\psi_{t,e}+K_2\pi_ex_{t,e}\notag \\
		&+\sum_{t \in T}\sum_{f \in F} 	K_1\pi_f\psi_{t,f}+K_2\pi_fx_{t,f}\notag \\
		&+\sum_{t \in T}\sum_{c \in C} K_1\pi_c\psi_{t,c}+K_2\pi_cx_{t,c} \label{eqn:objective_func_final} \notag \\
		&s.t. 
		\cref{eqn:constraint_load_conservation_computing_nodes}
		\cref{eqn:constraint_request_flow_existence}				\cref{eqn:constraint_psi}
		\cref{eqn:constraint_load_managing_new} \notag \\
		&\cref{eqn:constraint_delay_last}
		\cref{eqn:constraint_queue_stability}
		\cref{eqn:constraint_load_conservation_sensor_nodes_coupling}
		\cref{eqn:constraint_scalability_coupling}
	\end{align}
	
	\section{راه‌حل غیرمتمرکز}
	در این بخش قرار است که مسئله بهینه‌سازی نهایی که در \cref{eqn:objective_func_final} نوشته شد به صورت غیرمتمرکز حل شود. 
	همانطور که در قسمت بررسی قیدهای مربوط به مسئله اصلی گفته شد، بجز دو قید از قیدهای مسئله که به صورت متصل بودند بقیه قیدها این قابلیت را داشتند که بین گره‌ها تجزیه شوند. 
	\subsection{راه‌حل غیرمتمرکز برای مسئله milp}
	در این بخش ابتدا با ارچاع به یکی از مقاله‌های موجود در این زمینه در مورد نجوه‌ی حل مسائل milp به صورت غیرمتمرکز صحبت می‌شود و در ادامه این راه حل ارائه شده بر روی مسئله اصلی اجرا می‌شود. 
	در مقاله \cite{decentralized_approach} به صورت کامل در مورد روش غیرمتمرکز صحبت شده است با ارجاع به این مقاله در ادامه این روش را مورد بررسی قرار می‌دهیم. 
	
	فرض کنید که مسئله milp به صورت \cref{eqn:cite_def_milp} نوشته شده باشد. 
	\begin{subequations}
		\begin{align}\label{eqn:cite_def_milp}
			&\min_{x_1,..,x_m} \sum_{i=1}^m c_i^Tx_i \notag \\
			&\text{subject to:} \sum_{i=1}^m A_ix_i \le b \notag \\
			&\quad\quad x_i \in X_i, i = 1,..,m
		\end{align}
		\begin{align}
			&b \in R^p \notag \\
			&X_i = \{x_i\in R^{n_{c,i}}*Z^{n_{d,i}}:D_ix_i \le d_i\}
		\end{align}
	\end{subequations}
	اگر برای مسئله \cref{eqn:cite_def_milp} رابطه‌ی مسئله‌ی تجزیه دوگان\LTRfootnote{Dual decomposition} را بنویسیم، آنگاه به \cref{eqn:cite_dual}  می‌رسیم. 
	\begin{equation}\label{eqn:cite_dual}
		\max_{\lambda > 0} -\lambda^Tb + \sum_{i=1}^m \min_{x_1,..,x_m}(c_i^T + \lambda^TA_i)x_i
	\end{equation}
	بعد از حل مسئله \cref{eqn:cite_dual} می‌توان متغیرهای اصلی یعنی $x$ را به صورت \cref{eqn:cite_x_from_dual} یافت. 
	\begin{align}\label{eqn:cite_x_from_dual}
		x(\lambda^*) = [x_1(\lambda^*)^T, ..., x_m(\lambda^*)^T]^T \notag \\
		x_i(\lambda) \in \arg \min_{x_i \in vert(X_i)} (c_i^T + \lambda^TA_i)x_i
	\end{align}
	%todo shor cite handling
	در مقاله \cite{decentralized_approach} با یک مثال نشان داده می‌شود که با طی کردن مراحل بالا برای یافتن جواب بهینه $x$، می‌توان تضمین کرد که شرایط محلی یعنی $x_i \in X_i$ حتما ارضا می‌شود اما متاسفانه نمی‌توان حتما تضمین کرد که قیدهای متصل نیز ارضا می‌شوند. راه حل احتمالی که به ذهن می‌رسد استفاده از راه حل ارائه شده در مقاله \cite{shor} است که در آنجا مسئله را از حالت milp به حالت lp تبدیل می‌کند، با این کار تضمین می‌شود که قیدهای متصل حتما ارضا شوند اما از آن طرف به دلیل وجود متغیرهای گسسته این احتمال وجود دارد که قیدهای محلی به طور کامل ارضا نشوند. بنابراین از این راه حل نیز نمی‌توان استفاده کرد. 
	
\begin{latin}
	\begin{algorithm}
		\caption{Decentralized milp from \cite{decentralized_approach}}
		\begin{algorithmic}[1]
			\Procedure{}{}       %\Comment{This is a test}
				\State $\lambda(0) = 0$
				\State $\bar{s}_i(0) = -\infty , i = 1,...,m$ 
				\State $\underline{s}_i(0) = +\infty , i = 1,...,m$ 
				\State k = 0
				
				\Repeat
					\For{$i = 1$ to $m$}
						\State $x_i(k+1) \gets \arg \min_{x_i \in vert(X_i)} (c_i^T + \lambda(k)^TA_i)x_i$
					\EndFor
					\State $\bar{s}_i(k+1) = \max\{\bar{s}_i(k), A_ix_i(k+1) \} , i = 1,...,m$
					\State $\underline{s}_i(k+1) = \min\{\underline{s}_i(k), A_ix_i(k+1) \} , i = 1,...,m$
					\State $\rho_i(k+1) = \bar{s}_i(k+1) - \underline{s}_i(k+1),  , i = 1,...,m$
					\State $\rho(k+1) = p \max \{ \rho_1(k+1), ..., \rho_m(k+1) \}$
					\State $\lambda(k+1) = [\lambda(k) + \alpha(k)(\sum_{i=1}^{m}A_ix_i(k+1)-b+\rho(k+1)]_+$
					\State $k \gets k+1$ 
				\Until{some stopping criterion is met.}
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}
\end{latin}
	
		 برای این کار ابتدا لاگرانژین تابع هدف را برای قیدهایی که به صورت متصل‌شده\LTRfootnote{Coupling} هستند یعنی قیدهای \cref{eqn:constraint_scalability_coupling} و \cref{eqn:constraint_load_conservation_sensor_nodes_coupling} می‌نویسیم که به فرم \cref{eqn:lagrangian_1} نوشته می‌شود.
		\begin{align}\label{eqn:lagrangian_1}
			& \notag L(\underline{\underline x}, \underline{\underline \beta}, \underline {\eta_1}, \underline {\eta_2}, \underline{\underline \nu}) = \sum_{t \in T}\sum_{e \in E} x_{t,e}\Gamma_{t,e} \\
			& \notag + \sum_{t \in T}\sum_{f \in F} x_{t,f}\Gamma_{t,f} + \sum_{t \in T}\sum_{c \in C} x_{t,c}\Gamma_{t,c} \\
			& \notag + \sum_{t \in T  }{\eta_{1,t}(1-\sum_{e \in E}x_{t,e} + \sum_{f \in F}x_{t,f} + \sum_{c \in C}x_{t,c})} \\
			& \notag + \sum_{t \in T}{\eta_{2,t}(\sum_{e \in E}x_{t,e} + \sum_{f \in F}x_{t,f} + \sum_{c \in C}x_{t,c}-N_t)} \\
			& + \sum_{t \in T}\sum_{s \in S}{\nu_{t,s}(\lambda_{t,s} - \sum_{e \in E}\beta_{t,s,e} + \sum_{f \in F}\beta_{t,s,f} +\sum_{c \in C}\beta_{t,s,c})}
		\end{align}
	در \cref{eqn:lagrangian_2} سعی شده است که کل تابع موجود بر روی گره‌های پردازشی تجزیه شود. بدین صورت که هر گره پردازشی تابع مخصوص به خود را داشته باشد. 
	\begin{subequations}
		\begin{align}
			& \notag L = \sum_{e \in E}\sum_{t \in T}(\sum_{s \in S}(\nu_{t,s}\beta_{t,s,e}+\frac{\nu_{t,s}\lambda_{t,s}}{3|E|}) \\
			&\notag + x_{t,e}(\Gamma_{t,e}-\eta_{1,t}+\eta_{2,t})+\frac{\eta_{1,t}-N_t\eta_{2,t}}{3|E|}) \\
			& \notag + \sum_{f \in F}\sum_{t \in T}(\sum_{s \in S}(\nu_{t,s}\beta_{t,s,f}+\frac{\nu_{t,s}\lambda_{t,s}}{3|F|}) \\
			& \notag + x_{t,f}(\Gamma_{t,f}-\eta_{1,t}+\eta_{2,t})+\frac{\eta_{1,t}-N_t\eta_{2,t}}{3|F|}) \\
			& \notag + \sum_{c \in C}\sum_{t \in T}(\sum_{s \in S}(\nu_{t,s}\beta_{t,s,c}+\frac{\nu_{t,s}\lambda_{t,s}}{3|C|}) \\
			&+ x_{t,c}(\Gamma_{t,c}-\eta_{1,t}+\eta_{2,t})+\frac{\eta_{1,t}-N_t\eta_{2,t}}{3|C|})
		\end{align}
		\begin{align}
			& L = \sum_{e \in E}L_e + \sum_{f \in F}L_f + \sum_{c \in C}L_c
		\end{align}
	\end{subequations}


	\begin{align}
		\lambda_{t,s} \le \sum_{e \in E} \beta_{t,s,e} + \sum_{f \in F} \beta_{t,s,f}
		+\sum_{c \in C}\beta_{t,s,c} \le \lambda_{t,s}+\epsilon \quad \forall{t \in T}, \forall{s \in S}
	\end{align}
    
    
    

    در یک منطقه جغرافیایی تعداد $N$ عدد سرویس و $M$ عدد فراهم کننده زیرساخت\LTRfootnote{Infrastructure Provider} پردازشی در نظر گرفته می‌شود.
    مجموعه سرویس‌ها را با $S$ و مجموع منابع پردازشی را با $C$ نمایش می‌دهیم.
    فراهم‌کننده‌های زیرساخت علاقه دارند که توان پردازشی اضافی خود را با دیگران به اشتراک بگذارند.
    در این فصل از $\phi_i$ برای بیان توان پردازشی فراهم‌کننده زیرساخت $i$ و از $\nu_i$ برای بیان درصدی از توان پردازشی که فراهم‌کننده زیرساخت پردازشی $i$ مایل به اشتراک‌گذاری آن است، استفاده می‌کنیم.
    در نتیجه، فراهم‌کننده زیرساخت پردازشی $i$ام، مایل به اشتراک‌گذاری توان پردازشی برابر با $\varphi_i = \phi_i \nu_i$ خواهد بود.
    در اینجا، گره‌های لبه\LTRfootnote{Edge Nodes}، گره‌هایی هستند که زیرساخت پردازشی را در لبه شبکه فراهم می‌کنند.
    در مقابل، فراهم‌کننده‌های زیرساخت ابری، منابع پردازشی را در فاصله‌ای دورتر از سرویس‌ها فراهم می‌کنند.
    بنابراین،‌ گره‌های لبه، توان پردازشی کم‌تر با تاخیر کم‌تر را در مقایسه با فراهم‌کننده‌های زیرساخت ابری مهیا می‌کنند.
    بده‌بستان\LTRfootnote{Trade-off}، بین میزان توان پردازشی و تاخیر در پردازش، باعث پیچیده‌شدن انتخاب گره‌های پردازشی برای سرویس‌ها می‌شود.
    
    \cref{tbl:one_to_one:notation} به صورت خلاصه پارامتر‌ها و متغیر‌های استفاده شده در این فصل را معرفی می‌کند.
    \begin{table}[h]
      \caption{نماد‌های استفاده شده در \cref{chap:one_to_one_allocation}}
      \begin{tabularx}{\textwidth}{|c|C|} \hline
        نشانه                & توضیح                                                                                     \\ \hline
        $C$                  & مجموعه‌ی گره‌های پردازشی لایه ابر                                                                       \\ \hline
        $F$                  & مجموعه‌ی گره‌های پردازشی لایه مه                                                                       \\ \hline
        $E$                  & مجموعه‌ی گره‌های پردازشی لایه لبه                                                                       \\ \hline
        $S$                  & مجموعه‌ی گره‌های لایه‌ی حسگر                                                                     \\ \hline                        
        $T$                  & مجموعه‌ی وظیفه‌های موجود در شبکه                                                                  \\ \hline
		$c$                  & اندیس مربوط به گره‌های پردازشی لایه‌ی ابر                                                                       \\ \hline
		$f$                  & اندیس مربوط به گره‌های پردازشی لایه‌ی مه                                                                       \\ \hline
		$e$                  & اندیس مربوط به گره‌های پردازشی لایه‌ی لبه                                                                       \\ \hline
		$s$                  & اندیس مربوط به گره‌های پردازشی لایه‌ی حسگر                                                                     \\ \hline                        
		$t$                  & اندیس مربوط به وظیفه‌ها                                                                  \\ \hline
        $\sigma$        	 & واحد قیمت پردازشی در گره‌ها                                                                \\ \hline
        
        $d_{i,s}^\text{CPU}$ & تاخیر پردازشی سرویس $s$ در صورتی که از منبع پردازشی $i$ استفاده کند                       \\ \hline
        $d_{i,s}^\text{net}$ & تاخیر انتقال داده‌ها سرویس $s$  در صورتی که از منبع پردازشی $i$ استفاده کند                \\ \hline
        $\mu_{i,s}$         & نرخ سرویس منبع پردازشی $i$ برای سرویس $s$                                                  \\ \hline
        $r_s$               & نرخ انتخابی ارسال نمونه‌های سرویس $s$                                                       \\ \hline
        $R_s$               & نرخ مطلوب ارسال نمونه‌ها برای سرویس $s$                                                     \\ \hline
        $\omega_s$          & ضریب وزن دهی برای مشخص کردن نسبت اهمیت تاخیر نسبت به اختلاف نرخ انتخابی و نرخ مطلوب برای سرویس‌ها \\ \hline
        $\delta_{i,s}$      & متغیر دودویی که مشخص می‌کند سرویس $s$ منبع پردازشی $i$ را استفاده می‌کند یا خیر              \\ \hline
        $f_r$               & تابع مشخص کننده تاثیر اختلاف نرخ انتخابی با نرخ مطلوب در ارزش سرویس                         \\ \hline
        $f_d$               & تابع مشخص کننده تاثیر تاخیر در ارزش سرویس                                                  \\ \hline
        $U_{i,s}$           & ارزش سرویس $s$ در صورتی که از منبع پردازشی $i$ استفاده کند                                 \\ \hline
        $U_s$               & ارزش سرویس $s$                                                                             \\ \hline
        $U$                 & مجموع ارزش سرویس‌ها                                                                         \\ \hline
        $\eta$              & پارامتر محدود کننده‌ی بهره برداری از منابع پردازشی                                          \\ \hline
        $\epsilon$          & حداقل مقدار افزایش قیمت منابع پردازشی توسط سرویس‌ها در هر پیشنهاد                           \\ \hline
        $p_i$               & قیمت استفاده از منبع پردازشی $i$                                                           \\ \hline
        $\iota_s$           & منبع پردازشی با بیش‌ترین سود برای سرویس $s$                                                 \\ \hline
        $v_s$               & سود بهترین منبع پردازشی برای سرویس $s$                                                     \\ \hline
        $w_s$               & سود دومین بهترین منبع پردازشی برای سرویس $s$                                               \\ \hline
        $\gamma_s$          & میزان افزایش قیمت برای بهترین منبع پردازشی سرویس $s$                                       \\ \hline
      \end{tabularx}
      \label{tbl:one_to_one:notation}
    \end{table}

    در ابتدا تاخیر سرویس‌ها را بررسی می‌کنیم.
    تاخیر سرویس $s$ زمانی که از منبع پردازشی $i$ استفاده می‌کند، از دوبخش تشکیل می‌شود.
    یکی مربوط به تاخیر شبکه‌ است که آن را با $d^\text{net}$ نمایش می‌دهیم.
    دیگری مربوط به تاخیر پردازش است که آن را با $d^\text{CPU}$ نمایش می‌دهیم.
    تاخیر شبکه ،$d^\text{net}$، زمانی است که لازم است تا حسگر‌‌های یک سرویس داده‌ها را برای منبع پردازشی اختصاص یافته ارسال کنند به علاوه زمانی که لازم است تا گره پردازشی نتیجه را برای مقصد ارسال کند.
    تاخیر پردازشی ،$d^\text{CPU}$، زمانی است که طول می‌کشد تا داده‌ها در منبع پردازشی، پردازش شوند.
    
    در این‌جا فرض می‌کنیم که تاخیر شبکه ثابت است و تنها تابع فاصله جغرافیایی و ادوات شبکه بین فرستنده و گیرنده است.
    همانند \cite{optimial_price_cloud_valerio} از تئوری صف برای مدل کردن تاخیر پردازشی استفاده می‌کنیم.
    در این روش، پردازنده مانند یک سرویس دهنده عمل می‌کند و درخواست‌ها در یک صف قرار می‌گیرند تا نوبت پردازش آن‌ها فرار برسد.
    چون در این فصل هر گره پردازشی تنها به یک سرویس اختصاص پیدا می‌کند، از مدل $M/D/1$ استفاده می‌کنیم.
    در این مدل، فرایند ورود به صف بدون حافظه بوده و نرخ سرویس‌ مقدار ثابتی دارد.
    برای یک صف $M/D/1$ با نرخ ورود $\lambda$ و نرخ سرویس  $\mu$ میانگین تاخیر $\omega$ از رابطه زیر بدست می‌آید\cite{basic_queueing_sztrik}
    \begin{equation}\label{eqn:md1_queue_responsetime}
      \omega = \frac{1}{\mu} + \frac{\lambda}{2\mu(\mu-\lambda)}.
    \end{equation}
    
    نرخ ارسال نمونه‌های حسگر‌های سرویس $s$ را $r_s$ می‌نامیم.
    در صورتی که سرویس $s$ از منبع پردازشی $i$ استفاده کند نرخ ورود در مدل $M/D/1$ برای منبع پردازشی $i$ برابر $r_s$ خواهد بود.
    همان‌گونه که قبلا توضیح داده شد، $\varphi_i$ بیان‌گر ظرفیت پردازشی است که منبع پردازشی $i$ مایل به اشتراک گذاری آن است.
    این عدد در واقع تعداد دستور العمل‌های پردازنده مرکزی\LTRfootnote{CPU Instructions} که این منبع پردازشی در یک ثانیه می‌تواند اجرا کند را بیان می‌دارد.
    اگر فرض کنیم $F_s$ تعداد دستور العمل‌های لازم برای پایان یافتن پردازش‌های یک نمونه از داده‌های حسگر های سرویس‌ $s$ را نشان دهد، نرخ سرویس منبع پردازشی $i$ برای سرویس $s$ از رابطه زیر بدست می‌آید
    \begin{equation}
      \mu_{i,s} = \frac{\varphi_i}{F_s}.
    \end{equation}
    با جایگذاری این مقدار در \cref{eqn:md1_queue_responsetime} تاخیر پردازشی سرویس $s$ وقتی از منبع پردازشی $i$ استفاده می‌کند به صورت زیر دست می‌آید:
    \begin{equation}
      d_{i,s}^{\text{CPU}} = \frac{2\mu_{i,s}-r_s}{2\mu_{i,s}(\mu_{i,s}-r_s)}.
    \end{equation}

    در این جا فرض می کنیم که ارزش منبع پردازشی $i$ برای سرویس $s$ از دو بخش تشکیل شده است.
    بخش اول، تابع نرخ ارسال نمونه‌ها توسط حسگر‌های سرویس $s$ به منبع پردازشی $i$ است.
    این تابع را $f_r$ نام‌گذاری می‌کنیم و فرض می‌کنیم که $f_r$ تابعی از نرخ ارسال نمونه‌ها توسط حسگر‌های سرویس $s$ و نرخ مطلوب آن سرویس می‌باشد.
    در واقع $f_r$ بیان کننده‌ی تاثیر $r_s$ در ارزش بدست آمده از پردازش اطلاعات برای سرویس‌ها است.
    بخش دوم هم تابعی از تاخیر ایجاد شده (مجموع تاخیر شبکه و تاخیر پردازش) است که آن را با $f_d$ نمایش می‌دهیم.
    اگر فرض کنیم $R_s$ نرخ ارسال مطلوب نمونه‌ها برای سرویس $s$ و $r_s$ نرخ ارسال نمونه‌های سرویس $s$ باشد، ارزشی که سرویس $s$ با استفاده از منبع پردازشی $i$ بدست می‌آورد را به صورت زیر می‌توان نوشت
    \begin{equation}
      U_{i,s}(r_s) = \alpha_s \left (\omega_s f_r(r_s, R_s) + (1-\omega_s) f_d(d_{i,s}^{\text{net}} + d_{i,s}^{\text{CPU}}) \right ) .
    \end{equation}
    نکته قابل توجهه در این رابطه این است که $\omega_s \in [0,1]$ یک ضریب وزن دهنده است که تعیین کننده نسبت تاثیر $f_r$ به $f_d$ است.
    اگر $\omega = 1$ باشد ضریب $f_d$ صفر خواهد بود، در نتیجه تاخیر اثری در ارزش بدست‌آمده برای سرویس نقشی نخواهد داشت.
    اما $\omega = 0$ بیان‌گر این است که نرخ اختصاص یافته برای سرویس اهمیتی ندارد و فقط تاخیر برای سرویس مهم است.
    واضح است که اگر $\omega = 0$ باشد، نرخی که ارزشی بدست آمده برای سرویس را بیشینه می‌کند $r_s = 0$ است.
    در نتیجه $\omega = 0$ نتیجه قابل قبولی نخواهد داشت.
    $\alpha_s$ برای اثر دادن ارزش ذاتی سرویس‌ها است.
    پس $\alpha_s$ برای سرویس با ارزش بالاتر، باید مقدار بیشتری داشته باشد.
    در ادامه برای نشان دادن اختصاص منبع پردازشی $i$ به سرویس $s$ از $\delta_{i,s}$ که به صورت زیر تعریف می‌شود استفاده می‌کنیم
    \begin{equation*}
      \delta_{i,s} = 
      \begin{cases}
        1, & \text{اگر منبع پردازشی $i$ به سرویس $s$ اختصاص پیدا کرده باشد} \\
        0, & \text{در غیر این صورت}
      \end{cases}.
    \end{equation*}
    با این تعریف ارزش بدست آمده برای سرویس $s$ از تخصیص منابع را می‌توان به صورت زیر بیان کرد
    \begin{equation}
      U_{s} =  \alpha_s \left (\omega_s  f_r(r_s, R_s) + (1-\omega_s) \sum_{i=1}^M \delta_{i,s} f_d(d_{i,s}^{\text{net}} + d_{i,s}^{\text{CPU}}) \right).
    \end{equation}
    در این رابطه به دلیل ضرب $\delta_{i,s}$ در $f_d$ فقط $f_d$ مربوط به منبع پردازشی اختصاص یافته به سرویس $s$ در $U_s$ تاثیر گذار خواهد بود.

    هدف ما تخصیص منابع پردازشی است به طوری که مجموع ارزش بدست آمده برای سرویس‌ها را بیشینه شود.
    ارزشی که همه سرویس‌ها از تخصیص منابع بدست می‌آورند را $U$ نام‌گذاری می‌کنیم که به صورت زیر تعریف می‌شود
    \begin{equation}
      U = \sum_{s=1}^N \alpha_s \left (\omega_s f_r(r_s, R_s) + (1-\omega_s) \sum_{i=1}^M \delta_{i,s} f_d(d_{i,s}^{\text{net}} + d_{i,s}^{\text{CPU}}) \right).
    \end{equation}
    در واقع $U$ تابع هدف مسئله است و می‌توانیم مسئله تخصیص منابع را به صورت مسئله بهینه سازی زیر بنویسیم
    \begin{subequations}
      \begin{align}
        \underset{r_s, \delta_{i,s}}{\text{maximize}} \qquad & \sum_{s=1}^N \alpha_s \left (\omega_s f_r(r_s, R_s) + (1-\omega_s) \sum_{i=1}^M \delta_{i,s} f_d(d_{i,s}^{\text{net}} + d_{i,s}^{\text{CPU}}) \right ) \\
        \text{\lr{subject  to}} \qquad & \nonumber \\
        & 0 \le r_s, \forall s \in S\label{eqn:rate_positiveness} \\
        & r_s \le \eta \sum_{i=1}^M \mu_{i,s}, \forall s \in S\label{eqn:rate_saturation}\\
        & \sum_{s=1}^N \delta_{i,s} \le 1, \forall i \in C \label{eqn:one_to_one:resource_quota}\\
        & \sum_{i=1}^M \delta_{i,s} \le 1, \forall s \in S \label{eqn:one_to_one:service_quota}\\
        & \delta_{i,s} \in \{0, 1\}, \forall s \in S, i \in C
      \end{align}
    \end{subequations}
    قید \eqref{eqn:rate_positiveness} بیان می‌کند که نرخ ارسال انتخاب شده برای سرویس‌ها باید مثبت باشد.
    قید \eqref{eqn:rate_saturation} برای جلوگیری از اشباع شدن منابع پردازشی است.
    در این قید، $0 < \eta < 1$ حداکثر مقدار بهره‌برداری از منابع پردازشی اختصاص یافته به سرویس‌ها را محدود می‌کند.
    نکته حائز اهمیت این است که در صف‌های $M/D/1$ واریانس تاخیر با افزایش بهره‌برداری از منابع افزایش می‌یابد \cite{basic_queueing_sztrik}.
    به همین دلیل با افزایش $\eta$ واریانس تاخیر سرویس‌ها افزایش پیدا می‌کند که خود می‌تواند باعث افزایش نا اطمینانی در سرویس‌ها شود.
    در نتیجه ممکن برای بعضی سرویس‌ها لازم باشد که $\eta$ به طور جداگانه بر حسب نیازشان محاسبه شود.
    همان‌گونه که قبلا بیان شد در این فصل فرض بر این است که تخصیص منابع یک به یک است یعنی هر سرویس می‌تواند حداکثر از یک منبع پردازشی استفاده کند و هر منبع پردازشی هم حداکثر به یک سرویسی اختصاص پیدا می‌کند.
    قید‌های \eqref{eqn:one_to_one:resource_quota} و \eqref{eqn:one_to_one:service_quota} وظیفه دارند این شرایط را برقرار سازند.
        
    تابع‌های $f_r$ و $f_d$ در تابع هدف بهینه‌سازی باید شرایط خاصی داشته باشند تا بتوان آن‌ها را مورد قبول دانست.
    $f_r$ باید تابع اختلاف $r_s$ و $R_s$ باشد و با افزایش این اختلاف، مقدار آن کاهش پیدا کند.
    $f_d$ هم باید با افزایش تاخیر‌ کاهش پیدا کند.
    در ادامه‌ی این فصل فرض می‌کنیم:
    \begin{align}
      f_r(r_s, R_s) & = -|R_s - r_s| \label{eqn:one_to_one:f_r}\\
      f_d(d^\text{CPU}_{i,s} + d^\text{net}_{i,s}) & = - d^\text{CPU}_{i,s} - d^\text{net}_{i,s}
    \end{align}
    واضح است که این توابع، شرایطی که در بالا بیان شده است را دارند.

    مسئله بهینه سازی معرفی شده در این بخش یک مسئله برنامه‌ریزی غیرخطی عدد صحیح مخلوط \LTRfootnote{Mixed Integer Nonlinear Programming} می‌باشد.
    این نوع مسائل به طور کلی به سختی حل می‌شوند \cite{bertsimas1997introduction}.
    تعداد زیاد متغیر‌های موجود در این مسئله به دلیل تعداد فراوان سرویس‌ها و منابع پردازشی در سناریو‌های مربوط به اینترنت اشیاء پیدا کردن جواب بهینه این مسئله را غیر عملی می‌کنند.
    به همین دلیل یک جواب زیر بهینه که به صورت عملی قابل محاسبه باشد مطلوب است.
    در بخش بعدی روشی مبتنی بر مزایده را معرفی می‌کنیم که پاسخ زیر بهینه این مسئله را به صورت عملی محاسبه می‌کند.

  \section{تخصیص منابع با استفاده از مزایده}
    در روش‌ تخصیص منابع مبتنی بر مزایده فرض می‌شود که یک سرویس باید مقدار پول $p_i$ را به منبع $i$ بپردازد تا بتواند از آن استفاده کند.
    در این روش برای هر سرویس سود را اختلاف بین ارزشی که آن منبع برای سرویس ایجاد می‌کند و پولی که برای بدست آوردن آن پرداخت می‌کند، تعریف می‌کنیم.
    از این رو هرکدام از سرویس‌ها تلاش می‌کنند تا منبعی را بدست بیاورند که بیشترین سود را برای آن‌ فراهم می‌کند.
    باید توجه داشت که در این جا منظور از منابع، همان منابع پردازشی می‌باشد.
    \subsection{مروری بر روش مزایده}
      اگر $\iota_s$ منبعی باشد که بیشترین سود را برای سرویس $s$ فراهم کند، در این صورت رابطه زیر برای سرویس $s$ و منابع پردازشی برقرار خواهد بود:
      \begin{align}\label{eqn:maximal_net_value}
        U_{\iota_s,s}^* - p_{\iota_s} \ge \max_i \{U_{i,s}^* - p_i\}.
      \end{align}
      اگر \cref{eqn:maximal_net_value} برای همه سرویس‌ها برقرار باشد، به آن تعادل اقتصادی\LTRfootnote{Economic Equilibrium} می‌گویند\cite{auction_algorithms_bertsekas}.
      در این نوع تعادل، تمام طرف‌های درگیر، از منابع اختصاص یافته راضی هستند چرا که هیچکدام نمی‌توانند سود خود را افزایش دهند.
      در نتیجه هیچ‌کس انگیزه‌ای برای تغییر منابع اختصاص یافته ندارد.
      با این وجود، پیدا کردن این تعادل عملی نیست.
      دلیل عملی نبودن پیدا کردن این تعادل این است که حالت‌هایی وجود دارد که در فرایند پیدا کردن این تعادل حلقه به وجود می‌آید و فرایند خاتمه پیدا نمی‌کند.
      به عبارت دیگر حالت‌هایی ممکن است وجود داشته باشد که دو یا چند سرویس، ارزش یکسانی برای تعدادی از منابع قائل باشند.
      این حالت مانع افزایش قیمت منابع می‌شود.
      در نتیجه فرایند حراج هیچ وقت پایان نمی‌یابد.
      برای حل این مشکل، \cite{auction_algorithms_bertsekas} الگوریتمی ارائه کرد که تلاش می‌کند یک تعادل تقریبی\LTRfootnote{Almost Equilibrium} راپیدا کند.
      
      در یک تعادل تقریبی، تفاوت بین سود هریک از سرویس‌ها از بهینه بودن،باید حداکثر به اندازه‌ی $\epsilon$ باشد.
      در نتیجه در یک تعادل تقریبی رابطه زیر برای همه سرویس‌ها برقرار است
      \begin{equation}\label{eqn:almost_equilibrium}
        U_{\iota_s,s}^* - p_{\iota_s} \ge \max_i \{U_{i,s}^* - p_i\} - \epsilon.
      \end{equation}
      این رابطه برای هر سرویسی که برقرار باشد آن سرویس تقریبا راضی\LTRfootnote{Almost Happy} است.
      در واقع آن سرویس با تغییر منبعی که انتخاب کرده نمی‌تواند سود خود را بیشتر از $\epsilon$ افزایش دهد.
      این شرط با نام \lr{$\epsilon$ - complementary~slackness} شناخته می‌شود و در صورتی که $\epsilon = 0$ باشد، نتایج مانند تعادلی که توسط \cref{eqn:maximal_net_value} معرفی شد، خواهد داشت.
      الگوریتم معرفی شده، یک روش مبتنی بر تکرار است که بالاخره یک تعادل تقریبی را پیدا می‌کند.

      در ابتدا هرکدام از سرویس‌ها، منبع پردازشی که بیشترین سود را برایش فراهم می‌کند برمی‌گزیند.
      در این رابطه، $\iota_s$ بهترین منبع پردازشی را برای سرویس $s$ مشخص می‌کند.
      بنابراین رابطه زیر برای $\iota_s$ برقرار است:
      \begin{equation}\label{eqn:argmax_benefit}
        \iota_s = \argmax{i}\{U_{i,s}^* - p_i\}.
      \end{equation}
      سپس پیشنهاد دهنده (در این جا سرویس $s$) مبلغ پیشنهادی را برای منبع پردازشی $\iota_s$ به اندازه $\gamma_s$ بالا می‌برد
      \begin{equation}\label{eqn:bid_increase_1}
        \gamma_s = v_s - w_s + \epsilon,
      \end{equation}
      به طوری که $v_s$ بیشترین سودی است که سرویس $s$ می‌تواند بدست آورد
      \begin{equation}\label{eqn:bid_increase_2}
        v_s = \max_i\{U_{i,s}^* - p_i\},
      \end{equation}
      و $w_s$ بیشترین سودی است که سرویس $s$ بدست می‌آورد وقتی که $\iota_s$ از لیست منابع پردازشی حذف شود
      \begin{equation}\label{eqn:bid_increase_3}
        w_s = \max_{i \ne \iota_s}\{U_{i,s}^* - p_i\}.
      \end{equation}
      باید توجه کرد که $\gamma_s$ بیشترین مقداری است که قیمت منبع پردازشی $\iota_s$ می‌تواند افزایش پیدا کند به طوری که با اختصاص منبع پردازشی $\iota_s$ به سرویس $s$، آن سرویس تقریبا راضی باشد.
      بنابراین قیمت پیشنهادی جدید از رابطه زیر بدست می‌آید:
      \begin{equation}\label{eqn:bid_increase_4}
        p_{\iota_s} = p_{\iota_s} + \gamma_s.
      \end{equation}
      پس از این افزایش قیمت، سود بهترین منبع پردازشی (منبع پردازشی $\iota_s$) قبل از افزایش قیمت به اندازه‌ی $\epsilon$ کم‌تر از سود دومین منبع پردازشی قبل از افزایش قیمت خواهد بود.
      نکته‌ی قابل توجه در این افزایش قیمت این است که در حالتی که $\epsilon = 0$ باشد، پس از افزایش قیمت تفاوتی بین منبع پردازشی اول و منبع پردازشی دوم از لحاظ سود حاصل شده وجود ندارد.

      بعد از هر پیشنهاد قیمت، منبع پردازشی قیمت جدید را به همه اعلام می‌کند.
      در نتیجه سرویسی که قبلا بیشترین قیمت را پیشنهاد داده بود متوجه می‌شود که دیگر بیشترین پیشنهاد دهنده برای منبع پردازشی مربوطه نیست.
      این روش تاجایی ادامه پیدا می‌کند که قیمت منابع تاجایی بالا برود که فقط یک سرویس مایل به پرداخت آن قیمت برای بدست‌آوردن منبع پردازشی متناظر بشود.
      همان‌گونه که در \cite{auction_algorithms_bertsekas} بیان شده، $\gamma_s$ می‌تواند هر مقداری بزرگ‌تر از $\epsilon$ باشد ولی باید توجه داشت که مقادیر کوچکتر برای $\gamma_s$ موجب می‌شود که قیمت‌ها با قدم‌های کوچک‌تری در هر مرحله افزایش پیدا کنند.
      در نتیجه، افزایش قیمت پیشنهادی با میزانی کم‌تر از $\gamma_s$ باعث افزایش تعداد تکرار مراحل مزایده می‌شود.

    \subsection{معرفی الگوریتم تخصیص منابع مبتنی بر مزایده}
      در این جا از یک الگوریتم تکرار شونده برای اختصاص منابع پردازشی به سرویس‌ها استفاده می‌کنیم.
      در مرحله اول هر سرویس باید ارزشی که هر منبع پردازشی برایش دارد را محاسبه کند.
      برای این منظور باید نرخ بهینه ارسال اطلاعات را برای هر کدام از منابع پردازشی پیدا کند.
      فرض کنید $r_{i,s}^*$ نرخ بهینه برای سرویس $s$ وقتی از منبع پردازشی $i$ استفاده می‌کند باشد.
      در لم (\ref{lem:optimal_rate}) این نرخ بهینه را برای هر سرویس و هر منبع پردازشی پیدا می‌کنیم.
      اما ابتدا نیاز به لم زیر داریم.
      به کمک این لم می‌توانیم قدر مطلق را از \cref{eqn:one_to_one:f_r} حذف کنیم.
      \begin{lemma}\label{lem:optimal_rate_positive}
        برای سرویس $s$ وقتی از منبع پردازشی $i$ استفاده می‌کند, نرخ بهینه کم‌تر از $R_s$ است.
      \end{lemma}
      \begin{proof}
        برای اثبات از برهان خلف استفاده می‌کنیم.
        فرض کنید که $r_{i,s}^* \ge R_s$ نرخ بهینه سرویس $s$ وقتی از منبع پردازشی $i$ استفاده می‌کند باشد.
        باید توجه داشت که تابع ارزش هرکدام از منابع پردازشی برای سرویس‌ها ($U_{i,s}$) یک تابع نزولی نسبت به $r_{i,s}$ برای $r_{i,s} \ge R_s$ می‌باشد.
        چراکه هر دو بخش تشکیل دهنده این تابع برای $r_{i,s} \ge R_s$ با افزایش $r_{i,s}$ کاهش پیدا می‌کند.
        در نتیجه برای هر $\hat{r}_{i,s}$ به طوری که $r_{i,s}^* \ge \hat{r}_{i,s} \ge R_s$ رابطه $U(\hat{r}_{i,s}) \ge U(r_{i,s}^*)$ برقرار است که در تناقض با فرض اولیه است.
        در نتیجه نرخ بهینه کم‌تر از $R_s$ است.
      \end{proof}
      لم بعد، نرخ بهینه را برای سرویس $s$ وقتی از منبع پردازشی $i$ استفاده می‌کند را مشخص می‌کند.
      \begin{lemma}\label{lem:optimal_rate}
        اگر سرویس $s$ از منبع پردازشی $i$ استفاده کند نرخ بهینه از رابطه زیر بدست می‌آید:
        \begin{equation}\label{eqn:optimal_rate}
          r_{i,s}^* = \max\left\{0,\min\left\{R_s, \eta \mu_{i,s}, \mu_{i,s}-\frac{1}{2}\sqrt{2(1-\omega_s)/\omega_s}\right\}\right\}.
        \end{equation}
      \end{lemma}
      \begin{proof}
        با توجه به لم (\ref{lem:optimal_rate}) تابع ارزش منبع پردازشی $i$ برای سرویس $s$ با رابطه زیر قابل جایگزینی است:
        \begin{equation}
          (R_s - r_{i,s}) + \beta_s(d_{i,s}^{\text{net}} + d_{i,s}^{\text{cpu}}),
        \end{equation} 
        که در این رابطه $\beta_s=(1-\omega_s)/\omega_s$.
        این تابع یک تابع محدب است.
        پس برای پیدا کردن مقدار بهینه آن کافی است مشتق آن را مساوی صفر قرار دهیم و نتیجه را روی قید‌ها تصویر کنیم.
        \begin{align*}
          & \frac{\partial U_{i,s}}{\partial r_{i,s}} = 0 \\
          \Rightarrow &\frac{\partial}{\partial r_{i,s}}\{(R_s - r_{i,s}) + \beta_s(\sum_{i=1}^M d_{i,s}^{\text{net}} + d_{i,s}^{\text{cpu}})\} = 0 \\
          \Rightarrow & 1 + \beta_s[ \frac{1}{2\mu_{i,s}(\mu_{i,s}-r_{i,s}^*)} - \frac{2\mu_{i,s}-r_{i,s}^*}{2\mu_{i,s}(\mu_{i,s}-r_{i,s}^*)^2}] = 0 \\
          \Rightarrow & 2 {r_{i,s}^*}^2 - 4 \mu_{i,s} r_{i,s}^* + 2 \mu_{i,s}^2 - \beta_s = 0 \\
          \Rightarrow & r_{i,s}^* = \frac{4 \mu_{i,s} - \sqrt{16 \mu_{i,s}^2 - 8(2\mu_{i,s}^2 - \beta_s)}}{4} = \mu_{i,s} - \frac{\sqrt{2\beta_s}}{2}
        \end{align*}
        با تصویر کردن این رابطه روی قید‌های مسئله (\cref{eqn:rate_saturation,eqn:rate_positiveness}) به \cref{eqn:optimal_rate} می‌رسیم.
      \end{proof}  

      مراحل الگوریتم ارائه شده، در \cref{alg:one_to_one:auction} به صورت خلاصه بیان شده است.
      در ابتدا، هرکدام از منابع پردازشی، مقدار اولیه صفر را به عنوان قیمت برای خود انتخاب می‌کنند.
      سپس مراحل الگوریتم شروع می‌شود.
      در هر مرحله همه منابع کامپیوتری قیمت‌های خود را به سرویس‌ها اعلام می‌کنند.
      با استفاده از قیمت‌های اعلام شده هر سرویس بررسی می‌کند که هنوز بیشترین پیشنهاد را برای منبع پردازشی که در مرحله قبل انتخاب کرده دارد یا نه.
      اگر قیمت منبع پردازشی تغییر کرده بود یعنی دیگر بیشترین پیشنهاد را برای منبع پردازشی ندارد و باید منبع پردازشی و پیشنهاد جدید را دوباره انتخاب کند.
      برای این منظور با استفاده از \cref{eqn:argmax_benefit} و قیمت‌های جدید، منبع پردازشی با بیشترین سود را انتخاب می‌کند.
      سپس با استفاده از \crefrange{eqn:bid_increase_1}{eqn:bid_increase_4} قیمت پیشنهادی برای منبع پردازشی انتخاب شده را افزایش می‌دهد و آن را برای منبع پردازشی مربوطه ارسال می‌نماید.
      منابع پردازشی هم پس از دریافت پیشنهاد قیمت جدید، قیمت خود را به روزرسانی کرده و در مرحله بعد قیمت جدید را به اطلاع سرویس‌ها می‌رسانند.
      
      \begin{latin}
        \begin{algorithm}[tp]
          \caption{Auction ‌Based Resource Assignment Algorithm}
          \label{alg:one_to_one:auction}
          \begin{algorithmic}[1]
            \State{All computation resourcaes initialize their price with 0.} \label{state:auction_iteration:price_initialization}
            \While{There is atleast an unassigned service}
              \For {r in Computation Resources}
                \State{resource r broadcast its price to services}
              \EndFor
              \For {s in Services}
                \parState{Check the price of computation resource to see if the highest bidder of any resource. If not, change status to not assigned.} \label{state:service_iteration:check_assignment}
                \If{Not assigned to any computation resource}
                  \State{Find the computation resource having maximum benefit according to eq. \eqref{eqn:argmax_benefit}} \label{state:service_iteration:find_max}
                  \State{Compute new bid by using the eqs. \eqref{eqn:bid_increase_1} to \eqref{eqn:bid_increase_4}} \label{state:service_iteration:compute_new_bid}
                  \State{send the bid to the computation resource $I_s$} \label{state:service_iteration:send_bid}
                \EndIf
              \EndFor
              \For {r in Computation Resources}
                \If{received new bids}
                  \State{Update the price by the maximum bid.}
                \EndIf
              \EndFor
            \EndWhile
          \end{algorithmic}
        \end{algorithm}
      \end{latin}

    \subsection{بررسی هم‌گرایی}
      نویسنده در \cite{auction_algorithms_bertsekas} نشان داده که الگوریتم اختصاص منابع مبتنی بر مزایده بعد از تعداد محدودی تکرار، پایان می‌یابد.
      برای اثبات همگرایی باید توجه کرد تا زمانی که سروریس‌ها به یک منبع پردازشی اختصاص پیدا کرده‌اند، تقریبا راضی هستند.
      واضح است که سرویس‌ها به محض بدست‌آوردن منبع پردازشی تقریبا راضی هستند چرا که منبع پردازشی را با این شرط انتخاب می‌کنند.
      همچنین سرویس‌ها تا زمانی که یک منبع پردازشی را در اختیار دارند هم تقریبا راضی هستند.
      دلیل این موضوع این است که قیمت منابع پردازشی در هر مرحله کاهش پیدا نمی‌کند (ثابت باقی می‌ماند یا افزایش پیدا می‌کند).
      در نتیجه سود منابع پردازشی برای سرویس‌ها هرگز افزایش پیدا نمی‌کند.
      تا زمانی که قیمت یک منبع پردازشی تغییر نکند، سرویس مربوطه آن را در اختیار دارد و سود بقیه منابع پردازشی هم هرگز افزایش پیدا نمی‌کند،‌ پس تا زمانی که سرویس مربوطه آن منبع پردازشی را در اختیار دارد، \cref{eqn:almost_equilibrium} برقرار است.

      از مطالبی که در بالا بیان شد می‌توان نتیجه گرفت که منابع پردازشی پس از دریافت اولین پیشنهاد در همه مراحل به یک سرویس اختصاص دارند و تا پایان مزایده، آزاد نمی‌شوند.
      همچنین در هنگام پایان مزایده \cref{eqn:almost_equilibrium} برای همه سرویس‌ها برقرار است.
      پس در پایان، سرویس‌ها در یک تعادل تقریبی قرار دارند.
      بنا بر این، در حالتی که $N<M$، وقتی که $N$ گره‌ی پردازشی پیشنهاد دریافت کنند، هرکدام از سرویس‌ها به یکی از گره‌های پردازشی اختصاص پیدا کرده‌اند.
      پس شرط پایان الگوریتم برقرار می‌شود و الگوریتم پایان می‌یابد.

      با توجه به \cref{eqn:bid_increase_1} در هر مرحله وقتی یکی از منابع پردازشی یک پیشنهاد دریافت می‌کند، قیمتش حداقل به اندازه $\epsilon$ افزایش پیدا می‌کند.
      پس می‌توان نتیجه گرفت که پس از $m$ بار دریافت پیشنهاد جدید، قیمت منبع پردازشی مربوطه حداقل به اندازه‌ی $m\epsilon$ افزایش پیدا کرده است.
      برای مقادیر $m$ به اندازه کافی بزرگ، قیمت منبع پردازشی به اندازه‌ای افزایش پیدا کرده است که بعضی از سرویس‌ها پیشنهاد دادن به آن را متوقف کنند و شروع به پیشنهاد دادن به منابع پردازشی دیگر بکنند.
      همان طور که در بالا بیان شد وقتی این افزایش قیمت‌ها باعث شود که به $N$ منبع پردازشی پیشنهاد داده شود، الگوریتم پایان می‌یابد.
    \subsection{بررسی بهینگی الگوریتم}
      در \cite{distributed_auction_algorithms_zavlanos} نویسندگان ثابت کرده‌اند که نتیجه این الگوریتم حداکثر در فاصله $N\epsilon$ از مقدار بهینه قرار دارد.
      اگر $\alpha$ نشان دهنده نگاشت بین سرویس‌ها و گره‌های پردازشی باشد به طوری که $\alpha: \{1, \hdots, N\} \rightarrow \{1, \hdots, M\}$ , $\alpha(i) = \alpha_i$ آنگاه رابطه زیر برقرار است:
      \begin{equation}\label{eqn:auction_optimality_1}
        \sum_{i=1}^N U_{i,\alpha(i)}^* - \sum_{j=1}^M p_j \le \sum_{i=1}^N U_{i,\alpha(i)}^* - p_{\alpha(i)}.
      \end{equation}
      هم‌چنین واضح است که رابطه زیر برقرار است:
      \begin{equation}\label{eqn:auction_optimality_2}
        \sum_{i=1}^N U_{i,\alpha(i)}^* - p_{\alpha(i)} \le \sum_{i=1}^N \max_j\{U_{i,j}^* - p_j\}.
      \end{equation}
      با استفاده از \cref{eqn:auction_optimality_1,eqn:auction_optimality_2} می‌توان به رابطه زیر رسید:
      \begin{equation}\label{eqn:auction_optimality_3}
        \sum_{i=1}^N U_{i,\alpha(i)}^* \le \sum_{j=1}^M p_j + \sum_{i=1}^N \max_j\{U_{i,j}^* - p_j\}.
      \end{equation}
      تاکید می‌شود که \cref{eqn:auction_optimality_3} برای همه‌ی $\alpha \in \{1,\hdots,M\}$ و همه‌ی مجموعه قیمت‌های $\{p_j\}_{j=1}^M$ برقرار است.
      اگر مجموع ارزش حاصل از تخصیص منابع بهینه را $A^*$ بنامیم، برای $A^*$ رابطه زیر برقرار است:
      \begin{equation}\label{eqn:auction_optimality_A_defenition}
        A^* \triangleq \max_{\alpha(i),~i=1, \hdots, N} \sum_{i=1}^N U_{i, \alpha(i)}^*.
      \end{equation}
      اگر $D^*$ را به صورت زیر تعریف ‌کنیم:
      \begin{equation}\label{eqn:auction_optimality_D_defenition}
        D^* \triangleq \min_{p_j,~j=\{1, \hdots, m\}} \sum_{j=1}^M p_j + \sum_{i=1}^N \max_j\{U_{i,j}^* - p_j\}،
      \end{equation}
      آن‌گاه با توجه به \cref{eqn:auction_optimality_3} می‌توان نتیجه گرفت که $A^*<D^*$ است.
      
      هنگامی که الگوریتم مزایده به پایان می‌رسد، تخصیص منابع و قیمت‌های حاصل شده از الگوریتم، در تعادل تقریبی قرار دارند.
      اگر $\hat \alpha$ را تخصیص منابع حاصل از الگوریتم در نظر بگیریم، \cref{eqn:almost_equilibrium} را می‌توان به صورت زیر باز‌نویسی کرد:
      \begin{equation}\label{eqn:auction_almost_equilibrium2}
        U_{i, \hat \alpha(i)}^* - p_{\hat \alpha(i)} \ge \max_j \{U_{i,j}^*-p_j\}-\epsilon.
      \end{equation}
      از این رو می‌توان نتیجه گرفت که
      \begin{align}
        D^* & \le \sum_{i=1}^N \left(p_{\hat \alpha (i)}+\max_j\{U_{i,j}^*-p_j\}\right) \\
            & \le \sum_{i=1}^N U_{i, \hat \alpha (i)}^* + N \epsilon \label{eqn:auction_D_upper_bound}.
      \end{align}

      از این که $A^* \le D^*$ و \cref{eqn:auction_D_upper_bound} می‌توان نتیجه گرفت که
      \begin{equation}
        A^* - N \epsilon \le \sum_{i=1}^N U_{i, \hat \alpha (i)}^*.
      \end{equation}
      این رابطه بیان کننده یک حد پایین برای مجموع ارزش منابع اختصاص یافته توسط الگوریتم مزایده می‌باشد.
      درواقع این رابطه بیان می‌کند که نتیجه حداکثر در فاصله $N \epsilon$ مقدار بیشینه قرار دارد.
    \subsection{بررسی پیچیدگی الگوریتم}
      نویسندگان در \cite{distributed_auction_algorithms_zavlanos} پیچیدگی الگوریتم مزایده را بررسی کرده‌اند.
      برای بررسی پیچیدگی الگوریتم مزایده، بدترین حالت را در نظر می‌گیریم که در آن تمام سرویس‌ها قیمت پیشنهادی را در هر مرحله به اندازه $\epsilon > 0$ افزایش می‌دهند (تا جایی که منبع پردازشی برایشان جذاب نباشد).
      برای این منظور، فرض کنید $\delta > 0$ و $T_j>0$ و رابطه زیر برای $U_{i,j}^*, j=1,\hdots,M$ برقرار باشد
      \begin{gather}
        \max_i U_{i,j}^* - \min_i U_{i,j}^* < \delta \\
        \min_i U_{i,j}^* - \max_i U_{i,(j-1)}^* = T_j
      \end{gather}
      فرض کنید منبع پردازشی $N$ در ابتدا جذاب‌ترین منبع برای همه‌ی سرویس‌ها باشد.
      اگر $\delta$ به اندازه‌ی کافی کوچک باشد، قیمت آن باید حداقل به اندازه‌ی $T_N$ افزایش پیدا کند تا دیگر تنها منبع پردازشی جذاب نباشد.
      این مقدار افزایش قیمت نیاز به $\lceil T_N / \epsilon \rceil$ پیشنهاد توسط هر سرویس دارد.
      در نتیجه $N \lceil T_N / \epsilon \rceil$ تکرار طول می‌کشد تا دومین منبع پردازشی هم برای سرویس‌ها جذاب شود.
      حال که دو منبع پردازشی جذاب برای سرویس‌ها وجود دارد، هر سرویس باید $2 \lceil T_{N-1} / \epsilon \rceil$ پیشنهاد بدهد تا قیمت این دو منبع پردازشی به اندازه‌ای افزایش پیدا کند که منبع پردازشی سوم هم برای سرویس‌ها جذاب شود.
      واضح است این کار نیاز به $2N \lceil T_{N-1} / \epsilon \rceil$ تکرار الگوریتم دارد.
      به همین ترتیب می‌توان نتیجه گرفت که منبع پردازشی $N-k+1$ نیاز به $kN \lceil T_{N-k+1} / \epsilon \rceil$ تکرار الگوریتم دارد.
      با توجه به این که الگوریتم زمانی پایان خواهد یافت که حداقل $N$ منبع پردازشی پیشنهاد دریافت کنند، رابطه زیر را برای تعداد تکرار‌های الگوریتم می‌توان نوشت
      \begin{equation}
        N\sum_{k=1}^N k \left \lceil \frac{T_{N+k-1}}{\epsilon} \right\rceil < N ^ 2 \left \lceil \frac{\max_{i,j} \{U_{i,j}^*\} - \min_{i,j} \{U_{i,j}^*\}}{\epsilon} \right\rceil.
      \end{equation}
  \section{نتایج شبیه‌سازی}
    در این قسمت نتایج شبیه‌سازی را بیان می‌کنیم.
    در همه موارد شبیه‌سازی برای ۲۰۰ بار اجرا شده و نتایج میانگین آورده شده‌اند.
    یک شبکه با تعداد $N$ سرویس و $M$ منبع پردازشی که در داخل یک دایره به شعاع $R=\text{\lr{1Km}}$ به صورت تصادفی پراکنده ‌شده‌اند را در نظر می‌گیریم.
    برای هر سرویس عددی در بازه $[1,10]$ برای تعداد مقصد‌ها و در بازه $[1,5]$ برای تعداد منبع‌ها به صورت تصادفی در نظر می‌گیریم و فرض می‌کنیم منبع‌ها و مقصد‌های سرویس‌ها به صورت تصادفی در شعاع $20m$ از نقطه‌ی انتخاب شده برای سرویس پخش شده‌اند.
    فرض می‌کنیم شبکه از تعدادی دستگاه مسیریابی که به صورت سلسله مراتبی سازمان یافته اند،‌تشکل شده‌است.
    هر کدام از این دستگاه‌های مسیر‌یابی از نزدیک ترین دستگاه مسیریابی سطح بالاتر برای اتصال به شبکه استفاده می‌کند و دستگاه‌های مسیر یابی در بالاترین لایه با توپولوژی مش به هم متصل هستند.
    مبدأ‌ها و مقصدهای سرویس‌ها و منابع پردازشی که در لبه شبکه قرار دارند از نزدیک‌ترین مسیریاب در پایین ترین لایه استفاده می‌کنند.
    در مقابل، منابع پردازشی ابری از نزدیک‌ترین مسیریاب در بالاترین لایه استفاده می‌کنند.
    برای تاخیر مسیریاب‌ها فرض می‌کنیم که به صورت میانگین عبور بسته‌ها از مسیریاب‌های لایه ۱، ۱ میلی ثانیه، مسیریاب‌های لایه ۲، ۲ میلی ثانیه و مسیریاب‌های لایه ۳، ۳ میلی ثانیه طول می‌کشد.
    \cref{fig:network} توپولوژی شبکه را که در شبیه‌سازی استفاده شده‌است نشان می‌دهد.
    
    \begin{figure}[h]
      \centerline{\includegraphics[width=15cm]{graphics/one_to_one/network}}
      \caption{دید کلی از توپولوژی شبکه}
      \label{fig:network}
    \end{figure}

    برای مقدار $\eta$ هم ۰٫۹ را در نظر می‌گیریم و فرض می‌کنیم ظرفیت پردازشی منابع پردازشی لبه شبکه به صورت تصادفی در محدوده‌ی $[1200, 1400]$ توزیع شده‌اند.
    برای ظرفیت پردازشی منابع پردازشی ابری هم مقدار ثابت $1000$ را در نظر می‌گیریم.
    علاوه بر این $\alpha_s$ به صورت تصادفی در بازه $[1, 10]$ توزیع شده است.
    در این فصل، برای هر سرویس تاخیر در حدود چند میلی ثانیه خواهد بود.
    در نتیجه برای رسیدن به نتایج معنی دار فرض می‌کنیم که $\beta_s = (1-\omega_s)/\omega_s$ به صورت یکنواخت در بازه $[30,70]$ توزیع شده اند.
    
    فرض می‌کنیم که تعداد سرویس‌ها $N=300$ باشد و تعداد منابع پردازشی لبه شبکه ($M$) از ۳۹۰ تا ۱۰۰۰ تغییر کند.
    در این قسمت هزینه سرویس $s$ را $-U_s$ تعریف می‌کنیم. 
    در نتیجه میانگین هزینه سرویس‌ها برابر خواهد بود با $-U/N$.
    دو سناریو را در نظر می‌گیریم.
    در سناریو‌ی اول فرض می‌کنیم که فقط منابع پردازشی لبه شبکه وجود دارند ولی در سناریو دوم یک فراهم کننده ابری با ۴۰ منبع پردازشی هم در شبکه حضور دارد.
    
    \begin{figure}
      \centerline{\includegraphics[width=17cm]{graphics/one_to_one/sim_1}}
      \caption{میانگین هزینه سرویس‌ها در برابر تعداد منابع پردازشی در لبه شبکه}
      \label{fig:ono_to_one:sim1}
    \end{figure}

    \cref{fig:ono_to_one:sim1} نتیجه شبیه سازی را برای سناریو‌های بیان شده نشان می‌دهد.
    برای مقایسه، نتیجه حاصل از اختصاص نزدیک‌ترین منبع پردازشی و تخصیص منابع مبتنی بر تئوری تطبیق \cite{gale1962college} در شکل آورده شده است.
    در اختصاص نزدیک‌ترین منبع پردازشی، هر سرویس از نزدیک‌ترین منبع پردازشی به خود استفاده می‌کند.
    در اختصاص منابع پردازشی مبتنی بر تئوری تطبیق، منابع پردازشی لیست سرویس‌ها را به ترتیب اولویت نگه می‌دارند.
    هم‌چنین، سرویس‌ها هم لیست منابع پردازشی مورد علاقه خود را به ترتیب اولویت نگه می‌دارند.
    سپس سرویس‌ها به بهترین منبع پردازشی لیست خود درخواست می‌دهند.
    منابع پردازشی پس از دریافت درخواست بهترین را انتخاب می‌کنند و بقیه را رد می‌کنند.
    با رد شدن درخواست سرویس، سرویس مربوطه منبع پردازشی که درخواست را رد کرده از لیست خود حذف می‌کند و به منبع پردازشی بعدی درخواست می‌دهد.
    در \cite{gale1962college} همگرایی این الگوریتم ثابت شده‌است و نشان داده شده‌است که نتیجه، تطبیق پایداری است که مجموع سود سرویس‌ها را بیشینه می‌کند.
    این الگوریتم مانند الگوریتم مبتنی بر مزایده دارای پیچیدگی $O(N^2)$ می باشد \cite{mcvitie1970stable}.
    همان‌طور که از شکل مشخص است، تخصیص منابع مبتنی بر مزایده نتیجه بهتری نسبت به اختصاص نزدیک‌ترین منبع و اختصاص منابع مبتنی بر تئوری تطبیق دارد.
    زمانی که الگوریتم تخصیصی منابع پردازشی مبتنی بر حراج پایان می‌یابد، $U$ حداکثر به اندازه‌ی $N\epsilon$ با مقدار بیشینه فاصله دارد.
    بنابراین هنگامی که الگوریتم پایان می‌یابد میانگین هزینه سرویس‌ها حداکثر به اندازه $\epsilon$ با مقدار کمینه فاصله دارد.
    در نتیجه برای مقادیر کوچک $\epsilon$ میانگین هزینه‌ها مقداری نزدیک به بهینه را خواهد داشت.

    از \cref{fig:ono_to_one:sim1} می‌توان استنباط کرد که با افزایش تعداد منابع پردازشی، میانگین هزینه‌ی سرویس‌ها کاهش پیدا می‌کند.
    افزایش تعداد منابع پردازشی باعث افزایش احتمال یافتن منبع پردازشی بهتر برای هر سرویس می‌شود.
    پس کاهش هزینه، نتیجه‌ای قابل قبول برای افزایش تعداد منابع پردازشی می‌باشد.
    نکته‌ی دیگری که می‌توان از این شکل برداشت کرد این است که با افزایش تعداد گره‌های پردازشی، فاصله‌ی بین میانگین هزینه سرویس‌ها در سناریو‌ای که فراهم کننده منابع پردازشی ابری حضور دارد با سناریو‌ای که فراهم کننده منابع پردازشی ابری حضور ندارد کم می‌شود.
    دلیلی که می‌توان برای آن تصور کرد این است که با افزایش تعداد گره‌های پردازشی لبه شبکه احتمال اینکه سرویس‌ها، گره‌های پردازشی لبه شبکه را انتخاب کنند بیشتر می‌شود در نتیجه سرویس‌های کمتری از منابع پردازشی ابری استفاده خواهند کرد.
    با کاهش تعداد سرویس‌هایی که از منابع پردازشی ابری استفاده می‌کنند، اثر آن‌ها در میانگین هزینه سرویس‌ها کاهش پیدا می‌کند.
    در نتیجه تفاوت دو سناریو کاهش پیدا می‌کند.

    \begin{figure}
      \centerline{\includegraphics[width=17cm]{graphics/one_to_one/sim_2}}
      \caption{تاثیر $\beta$ بر تاخیر و اختلاف نرخ بهینه با نرخ مطلوب برای یک سرویس}
      \label{fig:ono_to_one:sim2}
    \end{figure}

    \cref{fig:ono_to_one:sim2} اثر $\beta$ روی میانگین تاخیر و میانگین اختلاف بین نرخ مطلوب و نرخ بهینه را برای یک سرویس نشان می‌دهد.
    در این شکل پارامتر‌های یاد شده برای $\beta \in [30, 70]$ رسم شده‌اند.
    در این‌جا فرض شده که همه پارامتر‌ها مانند قسمت قبل هستند و فرض شده که تأمین کننده‌ی منابع پردازشی ابری در شبکه حضور دارد.
    در این جا، $\beta$ بیان کننده نسبت اهمیت تاخیر به اختلاف نرخ مطلوب با نرخ بهینه است.
    به همین دلیل با افزایش $\beta$، اختلاف نرخ افرایش و تاخیر کاهش پیدا می‌کند.
    
    \begin{figure}
      \centerline{\includegraphics[width=17cm]{graphics/one_to_one/sim_3}}
      \caption{تاثیر $\alpha$ بر میانگین هزینه سرویس‌ها}
      \label{fig:ono_to_one:sim3}
    \end{figure}

    در \cref{fig:ono_to_one:sim3} تاثیر تغییر $\alpha_s$ بر روی هزینه یک سرویس‌ بررسی شده‌است.
    برای مقایسه، به جای رسم $-U_s$ برای سرویس، $-U_s/\alpha_s$ رسم شده‌است.
    واضح است که افزایش $\alpha_s$، باعث افزایش اثر تاخیر و اختلاف نرخ مطلوب و نرخ بهینه سرویس $s$ در تابع هدف بهینه سازی می‌شود.
    در نتیجه انتظار داریم با افزایش $\alpha_s$، $U_s/\alpha_s$ افزایش پیدا کند که \cref{fig:ono_to_one:sim3} این موضوع را تایید می‌کند.

    \begin{figure}
      \centerline{\includegraphics[width=17cm]{graphics/one_to_one/sim_4}}
      \caption{تاثیر تعداد سرویس‌ها بر میانگین هزینه سرویس‌ها}
      \label{fig:ono_to_one:sim4}
    \end{figure}

    \cref{fig:ono_to_one:sim4} تاثیر تعداد سرویس‌ها بر روی میانگین هزینه سرویس‌ها را وقتی تعداد منابع پردازشی ثابت است،‌نشان می‌دهد.
    برای مقایسه نتایج حاصل از الگوریتم تخصیص منابع مبتنی بر تئوری تطبیق نیز آورده‌شده است.
    همانطور که از شکل مشخص است، الگوریتم تخصیص منابع مبتنی بر مزایده به نتایج بهتری می‌رسد چرا که نتیجه آن حداکثر در فاصله $\epsilon$ مقدار بهینه قرار دارد.
    واضح است که با ثابت بودن منابع پردازشی، افزایش تعداد سرویس‌ها باعث افزایش رقابت برای یافتن بهترین منبع پردازشی می‌شود.
    در نتیجه احتمال دریافت بهترین منبع توسط منابع پردازشی کم‌ می‌شود.

    \begin{figure}[H]
      \centerline{\includegraphics[width=17cm]{graphics/one_to_one/sim_5}}
      \caption{تاثیر $\epsilon$ بر میانگین هزینه‌ی همه‌ی سرویس‌ها}
      \label{fig:ono_to_one:sim5}
    \end{figure}

    در انتها در \cref{fig:ono_to_one:sim5} تاثیر $\epsilon$ بر نتیجه تخصیص منابع مشاهده می‌شود.
    مطابق مطالب بیان شده درباره‌ی روش تخصیص منابع مبتنی بر حراج با افزایش $\epsilon$ حد اکثر فاصله‌ی تخصیص منابع با مقدار بهینه بیشتر می‌شود و \cref{fig:ono_to_one:sim5} این موضوع را تأیید می‌کند.

  \section{جمع‌بندی و نتیجه‌گیری}
    در این فصل صورت مسئله تخصیص منابع پردازشی به صورت یک به یک برای سرویس‌های اینترنت اشیاء در یک شبکه بررسی شد.
    سپس الگوریتمی مبتنی بر مزایده معرفی  شد که مسئله فوق را در زمان قابل قبول حل می‌کند.
    پس از آن همگرایی، پیچیدگی و بهینگی الگوریتم مبتنی بر مزایده بررسی شد که نشان می‌داد این الگوریتم، الگوریتم مناسبی برای استفاده در تخصیص منابع در شبکه اینترنت اشیاء است.
    در انتها نتیجه شبیه‌سازی‌ برای بررسی کارایی تخصیص منابع پردازشی توسط مزایده ارائه شد.
